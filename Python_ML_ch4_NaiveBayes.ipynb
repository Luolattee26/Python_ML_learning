{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e7c8a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3\n",
    "# 手写一个朴素贝叶斯的代码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0bfc253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 这里的朴素贝叶斯用的是高斯模型，相对的还有多项式模型以及伯努利模型\n",
    "# 不同的模型描述的就是贝叶斯公式中条件概率满足的不同分布\n",
    "# 比如这里的高斯分布，则表示条件概率满足高斯分布的那个公式，可以用样本方差以及均值去计算概率的大小\n",
    "# 一般情况下高斯模型用的最为广泛，所以手写高斯模型，sklearn里面同样有其他模型现成的库可以用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f5f05f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "22af5812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.4, 2.9, 4.3, 1.3],\n",
       "       [5.8, 2.7, 4.1, 1. ],\n",
       "       [5.1, 3.4, 1.5, 0.2],\n",
       "       [5.4, 3.9, 1.3, 0.4],\n",
       "       [5. , 2. , 3.5, 1. ],\n",
       "       [4.6, 3.6, 1. , 0.2],\n",
       "       [5.8, 2.7, 3.9, 1.2],\n",
       "       [4.8, 3. , 1.4, 0.1],\n",
       "       [4.8, 3.4, 1.9, 0.2],\n",
       "       [5. , 3.4, 1.6, 0.4],\n",
       "       [6.9, 3.1, 4.9, 1.5],\n",
       "       [6.3, 2.3, 4.4, 1.3],\n",
       "       [5.5, 2.4, 3.7, 1. ],\n",
       "       [5.2, 3.5, 1.5, 0.2],\n",
       "       [5. , 3.6, 1.4, 0.2],\n",
       "       [5.2, 3.4, 1.4, 0.2],\n",
       "       [5.1, 3.7, 1.5, 0.4],\n",
       "       [4.9, 3.6, 1.4, 0.1],\n",
       "       [6.2, 2.2, 4.5, 1.5],\n",
       "       [5.5, 2.5, 4. , 1.3],\n",
       "       [5. , 3.5, 1.6, 0.6],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [4.8, 3.1, 1.6, 0.2],\n",
       "       [6.6, 2.9, 4.6, 1.3],\n",
       "       [4.9, 3. , 1.4, 0.2],\n",
       "       [5.5, 2.6, 4.4, 1.2],\n",
       "       [6.7, 3.1, 4.4, 1.4],\n",
       "       [4.5, 2.3, 1.3, 0.3],\n",
       "       [6.3, 2.5, 4.9, 1.5],\n",
       "       [4.4, 2.9, 1.4, 0.2],\n",
       "       [4.3, 3. , 1.1, 0.1],\n",
       "       [5. , 3.3, 1.4, 0.2],\n",
       "       [5. , 3.2, 1.2, 0.2],\n",
       "       [5.3, 3.7, 1.5, 0.2],\n",
       "       [5.8, 4. , 1.2, 0.2],\n",
       "       [5.5, 3.5, 1.3, 0.2],\n",
       "       [5.4, 3.7, 1.5, 0.2],\n",
       "       [4.7, 3.2, 1.3, 0.2],\n",
       "       [5.1, 3.8, 1.6, 0.2],\n",
       "       [6.1, 2.9, 4.7, 1.4],\n",
       "       [4.6, 3.1, 1.5, 0.2],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [5.1, 3.5, 1.4, 0.2],\n",
       "       [5.1, 2.5, 3. , 1.1],\n",
       "       [5. , 3.5, 1.3, 0.3],\n",
       "       [4.9, 3.1, 1.5, 0.1],\n",
       "       [4.6, 3.2, 1.4, 0.2],\n",
       "       [4.4, 3.2, 1.3, 0.2],\n",
       "       [6.5, 2.8, 4.6, 1.5],\n",
       "       [5.1, 3.5, 1.4, 0.3],\n",
       "       [5.9, 3. , 4.2, 1.5],\n",
       "       [5.7, 2.9, 4.2, 1.3],\n",
       "       [6. , 3.4, 4.5, 1.6],\n",
       "       [4.7, 3.2, 1.6, 0.2],\n",
       "       [6. , 2.2, 4. , 1. ],\n",
       "       [4.9, 3.1, 1.5, 0.2],\n",
       "       [5.8, 2.6, 4. , 1.2],\n",
       "       [5.6, 3. , 4.5, 1.5],\n",
       "       [6.7, 3. , 5. , 1.7],\n",
       "       [5.9, 3.2, 4.8, 1.8],\n",
       "       [5.4, 3. , 4.5, 1.5],\n",
       "       [5.4, 3.4, 1.7, 0.2],\n",
       "       [6.1, 2.8, 4. , 1.3],\n",
       "       [5.7, 2.8, 4.1, 1.3],\n",
       "       [5.6, 2.5, 3.9, 1.1],\n",
       "       [5.5, 2.4, 3.8, 1.1],\n",
       "       [5.4, 3.4, 1.5, 0.4],\n",
       "       [5.4, 3.9, 1.7, 0.4],\n",
       "       [5.6, 2.9, 3.6, 1.3],\n",
       "       [5.1, 3.8, 1.5, 0.3]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 数据集生成\n",
    "def creat_data():\n",
    "    iris = load_iris()\n",
    "    df = pd.DataFrame(iris.data, columns = iris.feature_names)\n",
    "    df['label'] = iris.target\n",
    "    df.columns = ['sepal length', 'sepal width', 'petal length', 'petal width', 'label']\n",
    "    # 上面的这些代码，其实就是取了我们需要的数据集，并且进行了一些修改，没什么重要的\n",
    "    data = np.array(df.iloc[:100, :]) # 取整个数据集的前100个\n",
    "    return data[:, :-1], data[:, -1] # 切片，和上面是一样的，label作为分类变量，也就是我们的Y\n",
    "\n",
    "X, y = creat_data()\n",
    "# 用函数来划分一下训练集以及测试集\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ec81ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 开始写GaussianNB的代码\n",
    "class NaiveBayes:\n",
    "    def __init__(self):\n",
    "        self.model = None\n",
    "        \n",
    "    # 数学期望\n",
    "    @staticmethod\n",
    "    def mean(X):\n",
    "        return sum(X)/float(len(X)) # 这里用float，个人认为只是引入float类型，方便后面计算\n",
    "    \n",
    "    # 标准差\n",
    "    def stdev(self, X):\n",
    "        avg = self.mean(X) # 用上面写的平均值函数算个平均值\n",
    "        return math.sqrt(sum([pow(x - avg, 2) for x in X]) / float(len(X))) # 注意这里计算方差时候用的数学函数\n",
    "        \n",
    "    # 我们最前面提到，这里写的是高斯模型，所以我们现在可以通过高斯模型来计算概率密度函数了（也即条件概率）\n",
    "    def gaussian_probability(self, x, mean, stdev):\n",
    "        exponent = math.exp(-(math.pow(x - mean, 2) / (2 * math.pow(stdev, 2)))) # 这个玩意其实就是高斯概率里面后面那个exp\n",
    "        return (1 / (math.sqrt(2 * math.pi) * stdev)) * exponent\n",
    "    \n",
    "    # 对输入的X_train进行预处理\n",
    "    def summarize(self, train_data):\n",
    "        # 前面提过，在Python里面*是一个可迭代对象的解包符号\n",
    "        # 这里的作用其实就是，针对训练集数据的每个特征，即每一列，将其解包后再合并起来，这样就能针对每个特征计算我们需要的均值和方差\n",
    "        summarize = [(self.mean(i), self.stdev(i)) for i in zip(*train_data)]\n",
    "        return summarize\n",
    "        \n",
    "    # 接下来就是针对我们的训练数据，去得到我们需要的模型信息\n",
    "    def fit(self, X, y):\n",
    "        labels = list(set(y)) # 取得类别信息\n",
    "        data = {label : [] for label in labels} # 这里用了一个字典，来储存分别属于不同类别（y）的训练集数据\n",
    "        for f, label in zip(X, y):\n",
    "            data[label].append(f) # 这一步就是往里面添加信息\n",
    "        self.model = { # 同样的用一个字典来构造模型\n",
    "            label : self.summarize(value) for label, value in data.items()\n",
    "            # 可以发现，我们这里是利用之前写的summarize函数，将训练集进行分类并且进行预处理，从而得到了训练集每个特征的均值与方差，构建出模型\n",
    "        }\n",
    "        return 'gaussianNB model training is done'\n",
    "        \n",
    "    # 接下来，有了模型，就可以对测试集的数据计算概率从而得出测试结果了\n",
    "    def calculate_probabilities(self, input_data): # 这里input其实就是我们想要预测的测试集\n",
    "        probabilities = {} # 因为在预测的时候，我们是针对每一个类别得出概率，所以显然用字典来储存预测结果是十分合适的\n",
    "        for label, value in self.model.items():\n",
    "            probabilities[label] = 1 # 设置一个初始值\n",
    "            for i in range(len(value)):\n",
    "                mean, stdev = value[i]\n",
    "                probabilities[label] *= self.gaussian_probability(input_data[i], mean, stdev) # 要注意，我们设置的probabilities初始值是1\n",
    "        return probabilities\n",
    "    \n",
    "    # 进行概率排序，得出预测类别\n",
    "    def predict(self, X_test):\n",
    "        label = sorted(self.calculate_probabilities(X_test).items(), key = lambda x : x[-1])[-1][0]\n",
    "        # 这里的几个index，lambda表示按照概率来从排序（默认从小到大）\n",
    "        # 后面-1表示取概率最大的，0表示取它的label\n",
    "        return label\n",
    "    \n",
    "    # 算准确度\n",
    "    def score(self, X_test, y_test):\n",
    "        right = 0\n",
    "        for X, y in zip(X_test, y_test):\n",
    "            label = self.predict(X)\n",
    "            if label == y:\n",
    "                right += 1\n",
    "        return right / float(len(X_test)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "26842ef1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "100.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 来测试一下模型，正确答案是0.0类别，score应该是100\n",
    "model = NaiveBayes()\n",
    "model.fit(X_train, y_train)\n",
    "print(model.predict([4.4,  3.2,  1.3,  0.2]))\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2b069721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.4\n",
    "# 用sklearn库来实现gaussianNB\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, MultinomialNB\n",
    "# 高斯模型、伯努利模型和多项式模型\n",
    "clf = GaussianNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "329f1167",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d2be6a59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.predict([[4.4,  3.2,  1.3,  0.2]])[0]\n",
    "# 其实这里也体现出了为啥要自己会写源代码，默认的这个输出格式确实不太好看......"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becdc611",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
